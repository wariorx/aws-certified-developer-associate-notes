# S3
* Standalone storage solution; not tied to Compute
* Retrieve data from anywhere on the web
* Object storage services; data is stored in a flat structure along with its metafata. 
* Grows or shrinks as objects are added or removed from it; pay for space used
* Containers are called **buckets** in which objects are stored. 
* Objecst have unique identifiers composed of bucket name + object key + version ID
* To create a bucket, you must specify the **bucket name and region**
* Data is stored in a minimum of **3 AZ** for standard s3 buckets

## Bucket Names
* Bucket names must be **globally unique accrosss all AWS accounts** in all Regions within a partition (grouping of regions)
  * Between 3-63 characters long
  * Only lower cased letters, numbers, dots, and hyphens
  * begin and end with letter or number
  * must not be formatted as an IP address
  * cannot be used by another AWS account in the same partition
* **Region partitions**
  * Standard Regions
  * China Regions
  * AWS GovCloud (US)

## Object Keys
* Uniquely identify an object within the S3 Bucket.
* The console uses special characters in the key (/) to display the flat structure  as if it was hierarchycal; IE a key of foo/bar/baz.txt and foo/bar/xyz.txt In this case, foo/bar/ is the **prefix**

## Use Cases
* **Backup and Restore**: highly redundant and available
* **Media hosting**: grows infintely, objecst can be up to **5TB**
* **Software delivery**: host applications for downloads
* **Data Lakes**: great scalability, pay only for what you use
* **Static Websites**: can host static websites (HTML, CSS, JS)
* **Static Content**: access objects over the web

## Security
* Buckets are private by default; all resources can only be viewed by the user or account that created the resource
* Buckets and objects can be made public OR limited to certain users

### IAM Policies
* IAM users, groups, and roles can be granted policies that define their actions; in this case s3 actions
  * Policies attached to resources are **resource-based** policies, while policies attached to users are **user policies**
* Use when you want to assign perissions for **many buckets**
* **Centralize** permission management into IAM
  
### Bucket Policies
* Also defined in JSON format, like IAM policies.
* Only attched to S3 buckets; applies only to the bucket it's attached to
* Specify actions allowed or denied on the bucket
* Use when need a simple way to do **cross-account access** to S3
* IAM policies hit **size limits**; s3 bucket policies have a larger size
  
### S3 Encryption
* Encryption in transit (HTTPS) and at rest (S3 SSE or KMS) at no additional cost
  
## Storage Classes
* By default, new uploads go to standard class.
* Users can freely move objects from buckets in one class to another
* Classes:
  * **Standard**: general purpose storage for cloud applications, websites, CDN, analyticsm etc.
  * **Intelligent-Tiering**: for data that has unknown or changing access patterns. Objects are stored in tiers, monitors data, and automatically moves data to the most cost-effective storage tier:
    * Frequent access
    * Infrequent access
    * Archieve
  * **Standard-Infrequent Access (S3 Standard-IA)**: data accessed less frequently but requires rapid access when needed. high-durability and throughput, low latency, low-per- GB storage price and per-GB retrieval fee. Ideal for long-term backup and recovery
  * **One Zone infrequent Access (One Zone IA)**: less expensive than standard IA; ideal for lowering costs at risk of data loss
  * **Glacier instant retrieval**: data rarely accessed and requires miliseconds of retrieval. Offers cost savings on data storage (68%) with the same latency and performance
  * **Glacier Flexible Retrieval**: archieve data that's accessed a few times per year. Data can be accessed in 1-5 minutes at a charge; or bulk accessed in 5-12 hours at no cost. ideal for disaster recovery and occasional data retrival
  * **Glacier Deep Archieve**: lowst-cost S3 storage class. Long-term retention and preservation of data accessed a few times a year. Default retrieabl time of 12 hours. Ideal for compliance storage
  * **S3 on Outposts**: Delivers object storage to on-prem AWS Outpost environments using S3 APIs and features. Great for satisfying local data residency requirements or need to keep data close to an on-prem location for performance
  
## Versioning
* Without versioning, objects with the same key always overwrite each other. this can be an issue with common names on objects and/or when version preservation is required
* When enabled, S3 versioning allows you to keep multiple versions of a single object in the same bucket while preserving old versions.
* When first enabled, a unique version ID is generated for ALL objects in the bucket and all objects uploaded after
* Recover from accidental delition or overwrite:
  1. Deleting an object puts a **delete marker** on it. Remove the marker to restore the objext
  2. You can always go back to the previous version
* Object versions still inquire costs; to minimize costs, delete older versions
* Versioning states of buckets:
  * **Unversioned (default)**: objects do not have a version
  * **Versioning enabled**: after enabling versioning, a bucket can never go to unversioned again. However, versioning can be suspended
  * **Versioning suspended**: new objects no longer have a version. However, previously existing objects might still have versions
  
## Storage lifecycle
* S3 offers automatic object lifecycle management through **lifecycle policies**
* Actions allowed:
  * **Transition actions**: define when objects should transition from one class to anoher
  * **Expiration actions**: define when objexts expire and should be permanently deleted
* Good ofr periodic logging (delete old logs) and data that changes in access frequency

## Bucket Replication
* Enables automatic, asynchronous copying of objects accross S3 Buckets
* Replicate data accross buckets in the same or different accounts
* Replicate data to a single or multipel destination buckets; in multuple or within the same AWS region
* **Live replication** objects are automatically written to downstream buckets as well. IE **Cross-Region Replication**
  * Destination bucket
  * IAM role that S3 can asume to replicate objects on your behalf
* **Batch replication** replicate existing objects to a bucket on demand
https://docs.aws.amazon.com/AmazonS3/latest/userguide/replication.html 